{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "F5o5Dr7o2C5J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import PIL\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image,ImageTk\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import pytesseract\n",
    "from pytesseract import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dr32MeZO2C5P",
    "outputId": "dff223f6-054c-487c-9fe0-3deb9dd37e78"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten\n",
    "from keras.models import Sequential, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5IPOJWj2C5Q",
    "outputId": "7a5a5097-404f-422c-8769-5c63ab04295c"
   },
   "outputs": [],
   "source": [
    "#location = input(\"Enter the location of the image : \")\n",
    "location = \"C:\\\\Users\\\\Aryan\\\\Shaan\\\\Coding\\\\04-Projects\\\\EXTRACT-script\\\\sentences\\\\say1.png\"\n",
    "image = cv2.imread(location,0)\n",
    "thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Zp38pZiS2C5S"
   },
   "outputs": [],
   "source": [
    "result = cv2.GaussianBlur(thresh, (5,5), 0)\n",
    "result = 255 - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "FHKgkjo62C5T"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite('final_img.png',result)\n",
    "loc = 'final_img.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "tz5pGi3o2C5U"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('DATA/train/.DS_Store'):\n",
    "    os.remove('DATA/train/.DS_Store')\n",
    "if os.path.isfile('DATA/test/.DS_Store'):\n",
    "    os.remove('DATA/test/.DS_Store')\n",
    "    \n",
    "for i in range(1,80):\n",
    "    if os.path.isfile(f'DATA/train/{i}/.DS_Store'):\n",
    "        os.remove(f'DATA/train/{i}/.DS_Store')\n",
    "    if os.path.isfile(f'DATA/test/{i}/.DS_Store'):\n",
    "        os.remove(f'DATA/test/{i}/.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Pyt90QGo2C5U"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                            zoom_range = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "4VqT-tOu2C5V",
    "outputId": "96a9a8fd-2f49-4e96-cbfd-ffe9bd20c79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 650 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "trained_image = datagen.flow_from_directory('DATA/train',\n",
    "                                            target_size = (32,32),\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Zw-MW1ks2C5W"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "38ldoY_n2C5X",
    "outputId": "0ba5bed9-6b96-482c-c973-df9606af5c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image = test_datagen.flow_from_directory('DATA/test',\n",
    "                                            target_size = (32,32),\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "diz2LPpK3soj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top = False, input_shape = (32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "VOqMlRV32C5X",
    "outputId": "d5b44379-464a-4328-d118-ade5d5947f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 18s 787ms/step - loss: 3.3318 - accuracy: 0.0431 - val_loss: 3.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 16s 755ms/step - loss: 3.2876 - accuracy: 0.0323 - val_loss: 3.2487 - val_accuracy: 0.0625\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 16s 771ms/step - loss: 3.1041 - accuracy: 0.0585 - val_loss: 2.8520 - val_accuracy: 0.0938\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 16s 766ms/step - loss: 2.8977 - accuracy: 0.1031 - val_loss: 2.6315 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 16s 765ms/step - loss: 2.5748 - accuracy: 0.1354 - val_loss: 2.4985 - val_accuracy: 0.0938\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 16s 764ms/step - loss: 2.3070 - accuracy: 0.1708 - val_loss: 2.1894 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 17s 803ms/step - loss: 2.1699 - accuracy: 0.1908 - val_loss: 2.0621 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 16s 773ms/step - loss: 2.1465 - accuracy: 0.1954 - val_loss: 1.8362 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 16s 769ms/step - loss: 1.8508 - accuracy: 0.2908 - val_loss: 1.7348 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 16s 772ms/step - loss: 1.5114 - accuracy: 0.3846 - val_loss: 1.1908 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 17s 814ms/step - loss: 1.4659 - accuracy: 0.4108 - val_loss: 1.0826 - val_accuracy: 0.5938\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 17s 792ms/step - loss: 1.1621 - accuracy: 0.5246 - val_loss: 0.7258 - val_accuracy: 0.6562\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 17s 786ms/step - loss: 0.9420 - accuracy: 0.6231 - val_loss: 1.1303 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 17s 800ms/step - loss: 0.8562 - accuracy: 0.6569 - val_loss: 0.6198 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 17s 789ms/step - loss: 1.4885 - accuracy: 0.4985 - val_loss: 1.0268 - val_accuracy: 0.5312\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.8445 - accuracy: 0.6338 - val_loss: 0.6323 - val_accuracy: 0.6562\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 17s 829ms/step - loss: 0.6836 - accuracy: 0.7185 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 16s 772ms/step - loss: 0.5411 - accuracy: 0.7862 - val_loss: 0.3959 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 16s 765ms/step - loss: 0.5920 - accuracy: 0.7723 - val_loss: 0.4458 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 16s 768ms/step - loss: 1.0462 - accuracy: 0.7400 - val_loss: 0.5168 - val_accuracy: 0.8125\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 16s 768ms/step - loss: 0.5111 - accuracy: 0.8046 - val_loss: 0.2997 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 16s 767ms/step - loss: 0.3382 - accuracy: 0.8754 - val_loss: 0.2622 - val_accuracy: 0.8438\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 16s 768ms/step - loss: 0.3181 - accuracy: 0.8723 - val_loss: 0.2159 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 16s 770ms/step - loss: 0.3803 - accuracy: 0.8800 - val_loss: 0.3380 - val_accuracy: 0.8438\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 16s 768ms/step - loss: 0.4586 - accuracy: 0.8477 - val_loss: 0.2786 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 16s 779ms/step - loss: 0.3561 - accuracy: 0.8738 - val_loss: 0.3387 - val_accuracy: 0.8438\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 16s 801ms/step - loss: 0.2444 - accuracy: 0.9154 - val_loss: 0.2294 - val_accuracy: 0.9062\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 16s 765ms/step - loss: 0.1269 - accuracy: 0.9523 - val_loss: 0.0627 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 16s 774ms/step - loss: 0.1652 - accuracy: 0.9323 - val_loss: 0.1148 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 16s 758ms/step - loss: 0.1052 - accuracy: 0.9615 - val_loss: 0.1960 - val_accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "def Train_Model():\n",
    "    global trained_image, test_image\n",
    "    model = Sequential()\n",
    "    conv_base = VGG16(weights='imagenet', include_top = False, input_shape = (32,32,3))\n",
    "    model.add(conv_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(26,activation = 'softmax'))\n",
    "    model.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(trained_image, epochs = 30, validation_data = test_image, validation_steps = 1)\n",
    "    model.save('model.h5')\n",
    "    \n",
    "Train_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "pPC8sgnL2C5Y"
   },
   "outputs": [],
   "source": [
    "def Predict_Model(img):\n",
    "    global trained_image\n",
    "    new_model = load_model('model.h5')\n",
    "    img = cv2.resize(img,(32,32),3)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = img / 255\n",
    "    letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','1','2','3','4','5','6','7','8','9','0',',',';',':','?','!','.','@','#','$','%','&','(',')','{','}','[',']']\n",
    "    \n",
    "    #prediction = new_model.predict_classes(img)\n",
    "    predict_x=new_model.predict(img) \n",
    "    \n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "    \n",
    "    prediction = classes_x[0]\n",
    "    \n",
    "    my_dict = dict(trained_image.class_indices)\n",
    "    \n",
    "    for key,value in my_dict.items():\n",
    "        if prediction == value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ZC13RDoE2C5Z"
   },
   "outputs": [],
   "source": [
    "def Word_Extract(location):\n",
    "    \n",
    "    if os.path.isdir('WORDS'):\n",
    "        shutil.rmtree('WORDS')\n",
    "        os.mkdir('WORDS')\n",
    "    else:\n",
    "        os.mkdir('WORDS')\n",
    "    img = PIL.Image.open(location)\n",
    "    d = pytesseract.image_to_data(Image.open(location) , output_type=Output.DICT)\n",
    "    n_boxes = len(d['level'])\n",
    "    select =[]\n",
    "    j =0\n",
    "    for i in range(n_boxes):\n",
    "        if d['text'][i] != '' and d['conf'][i] != '-1':\n",
    "            select.append(d['text'][i])\n",
    "            (x, y, w, h) = (d['left'][i]-20, d['top'][i]-20, d['width'][i]+20, d['height'][i]+20)\n",
    "            #cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            crop_img = img.crop((x,y,x+w,y+h))\n",
    "            crop_img.save(f'WORDS/{j}.png')\n",
    "            j += 1\n",
    "    \n",
    "    return  select\n",
    "      \n",
    "    \n",
    "select = Word_Extract(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Iy3jTM6U2C5Z"
   },
   "outputs": [],
   "source": [
    "if os.path.isdir('LETTERS'):\n",
    "    shutil.rmtree('LETTERS')\n",
    "    os.mkdir('LETTERS')\n",
    "else:\n",
    "    os.mkdir('LETTERS')\n",
    "    \n",
    "    \n",
    "for i in range(len(os.listdir('WORDS'))):\n",
    "    os.mkdir(f'LETTERS/{i}')\n",
    "    img = Image.open(f\"WORDS/{i}.png\")\n",
    "    img = img.resize((1600 , 800))\n",
    "    w,h = img.size\n",
    "    letters = pytesseract.image_to_boxes(img , output_type=Output.DICT)\n",
    "    letters\n",
    "    \n",
    "    idx = 0 \n",
    "    for c in range(len(letters['char'])): \n",
    "        \n",
    "        (x, y, w, h) = (letters['left'][c], letters['bottom'][c], letters['right'][c], letters['top'][c])\n",
    "        \n",
    "        crop_img = img.crop((x-50,y-50 , w+50,h+50))\n",
    "        crop_img.save(f\"LETTERS/{i}/\" + str(idx) + '.png')\n",
    "        idx+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "3Fx-5j4n2C5a"
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "for i in range(len(os.listdir('LETTERS'))):\n",
    "    string = ''\n",
    "    char_dict = {}\n",
    "    for j in range(len(os.listdir(f'LETTERS/{i}'))):\n",
    "        img = cv2.imread(f'LETTERS/{i}/{j}.png')\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        char = Predict_Model(img)\n",
    "        \n",
    "        \n",
    "        for l in range(len(select[i])):\n",
    "            if char == select[i][l]:\n",
    "                char_dict[select[i].index(char)] = char\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                for k in range(len(select[i])):\n",
    "                    if k != l:\n",
    "                        if char == select[i][k]:\n",
    "                            char_dict[k] = char \n",
    "        \n",
    "        keys = list(char_dict.keys())\n",
    "        if char not in select[i]:\n",
    "            for val in range(len(select[i])):\n",
    "                if val not in keys:\n",
    "                    char_dict[val] = char\n",
    "    keys = list(char_dict.keys())\n",
    "    keys.sort()\n",
    "    #print(keys)\n",
    "    \n",
    "    for m in keys:\n",
    "        string += char_dict[m]\n",
    "        \n",
    "        \n",
    "    string += ' '\n",
    "    text += string\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "AjpZgjRr2C5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The predicted sentence is:  H WQRQQ \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"\")\n",
    "print(\"The predicted sentence is: \",text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tesseract.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
